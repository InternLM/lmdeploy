name: evaluate_new

on:
  workflow_dispatch:
    inputs:
      repo_org:
        required: false
        description: 'Tested repository organization name. Default is InternLM/lmdeploy'
        type: string
        default: 'InternLM/lmdeploy'
      repo_ref:
        required: false
        description: 'Set branch or tag or commit id. Default is "main"'
        type: string
        default: 'main'
      chat_models:
        required: true
        description: 'Tested TurboMind models list. eg. [internlm_chat_7b,internlm_chat_7b_w8a16]'
        type: string
        default: '[turbomind_qwen3_32b, pytorch_qwen3_32b, turbomind_qwen3_30b_a3b, pytorch_qwen3_30b_a3b, turbomind_qwen3_30b_a3b_fp8, pytorch_qwen3_30b_a3b_fp8, turbomind_qwen3_235b_a22b, pytorch_qwen3_235b_a22b, turbomind_qwen3_235b_a22b_fp8, pytorch_qwen3_235b_a22b_fp8]'
      chat_datasets:
        required: true
        description: 'Tested datasets list. eg. [*bbh_datasets,*ceval_datasets,*cmmlu_datasets,*GaokaoBench_datasets,*gpqa_datasets,*gsm8k_datasets,*hellaswag_datasets,*humaneval_datasets,*ifeval_datasets,*math_datasets,*sanitized_mbpp_datasets,*mmlu_datasets,*nq_datasets,*race_datasets,*TheoremQA_datasets,*triviaqa_datasets,*winogrande_datasets,*crowspairs_datasets]'
        type: string
        default: '[*mmlu_datasets, *gsm8k_datasets, *ifeval_datasets]'
      base_models:
        required: true
        description: 'Tested TurboMind models list. eg. [turbomind_internlm2_5_7b, turbomind_internlm2_5_7b_4bits, turbomind_internlm2_5_7b_batch1, turbomind_internlm2_5_7b_batch1_4bits, turbomind_qwen2_7b, turbomind_qwen2_5_7b, turbomind_qwen2_5_14b]'
        type: string
        default: '[turbomind_qwen3_8b_base, pytorch_qwen3_8b_base]'
      baes_datasets:
        required: true
        description: 'Tested datasets list. eg. [*mmlu_datasets, *gsm8k_datasets]'
        type: string
        default: '[*race_datasets, *gsm8k_datasets, *gpqa_datasets, *winogrande_datasets]'
      oc_repo_org:
        required: false
        description: 'Tested repository organization name. Default is open-compass/opencompass'
        type: string
        default: 'open-compass/opencompass'
      oc_repo_ref:
        required: false
        description: 'Set branch or tag or commit id. Default is "main"'
        type: string
        default: 'main'
      offline_mode:
        required: true
        description: 'Whether start a offline mode, if true, you should prepare code and whl package by yourself'
        type: boolean
        default: false

env:
  ACTIONS_ALLOW_USE_UNSECURE_NODE_VERSION: true

jobs:
  linux-build:
    if: ${{github.event_name == 'schedule' || (!cancelled() && !inputs.offline_mode)}}
    strategy:
      matrix:
        pyver: [py312]
    runs-on: ubuntu-latest
    env:
      PYTHON_VERSION: ${{ matrix.pyver }}
      PLAT_NAME: manylinux2014_x86_64
      DOCKER_TAG: cuda12.4
      OUTPUT_FOLDER: cuda12.4_dist_${{ github.run_id }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          repository: ${{ github.event.inputs.repo_org || 'InternLM/lmdeploy' }}
          ref: ${{github.event.inputs.repo_ref || 'main'}}
      - name: Build
        run: |
          echo ${PYTHON_VERSION}
          echo ${PLAT_NAME}
          echo ${DOCKER_TAG}
          echo ${OUTPUT_FOLDER}
          echo ${GITHUB_RUN_ID}
          # remove -it
          sed -i 's/docker run --rm -it/docker run --rm/g' builder/manywheel/build_wheel.sh
          bash builder/manywheel/build_wheel.sh ${PYTHON_VERSION} ${PLAT_NAME} ${DOCKER_TAG} ${OUTPUT_FOLDER}
      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          if-no-files-found: error
          path: builder/manywheel/${{ env.OUTPUT_FOLDER }}
          retention-days: 1
          name: my-artifact-${{ github.run_id }}-${{ matrix.pyver }}

  evaluate:
    needs: linux-build
    if: ${{github.event_name == 'schedule' || !cancelled()}}
    runs-on: [self-hosted, linux-eval]
    timeout-minutes: 4320 # 72hours
    strategy:
      fail-fast: false
      matrix:
        evaluate_type: ['chat', 'base']
    env:
        HF_HUB_CACHE: /root/models
        HF_HUB_OFFLINE: 1
    container:
      image: pjlab-shanghai-acr-registry-vpc.cn-shanghai.cr.aliyuncs.com/pjlab-eflops/llm:lmdeploy-v0.7.2-cu12
      options: "--gpus=0,1,2,3,4,5 --ipc=host --user root -e PIP_CACHE_DIR=/root/.cache/pip -e NVIDIA_DISABLE_REQUIRE=1 --pull never"
      volumes:
        - /nvme1:/nvme1
        - /nvme2:/nvme2
        - /nvme1/shared/qa_test_models/pip-cache:/root/.cache/pip
        - /nvme1/shared/qa_test_models/opencompass-data:/root/opencompass-data
        - /nvme1/shared/qa_test_models/evaluation-reports:/root/evaluation-reports
        - /nvme2/huggingface_hub/hub:/root/models
        - /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro
    steps:
      - name: Setup systems
        run: |
          export TIME_STAMP="$(date +'%Y%m%d-%H%M%S')"
          echo "TIME_STAMP=$TIME_STAMP" >> $GITHUB_ENV
      - name: Clone repository
        uses: actions/checkout@v2
        if: ${{github.event_name == 'schedule' || !inputs.offline_mode}}
        with:
          repository: ${{ github.event.inputs.repo_org || 'InternLM/lmdeploy' }}
          ref: ${{github.event.inputs.repo_ref || 'main'}}
      - name: Copy repository - offline
        if: ${{inputs.offline_mode}}
        run: cp -r /nvme1/shared/qa_test_models/offline_pkg/lmdeploy/. .
      - name: Download Artifacts
        if: ${{github.event_name == 'schedule' || !inputs.offline_mode}}
        uses: actions/download-artifact@v4
        with:
          name: my-artifact-${{ github.run_id }}-py312
      - name: Install lmdeploy - dependency
        run: |
          # manually install flash attn
          # the install packeage from. https://github.com/Dao-AILab/flash-attention/releases
          python3 -m pip install -r /nvme1/shared/qa_test_models/offline_pkg/requirements.txt -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
      - name: Install lmdeploy
        if: ${{github.event_name == 'schedule' || !inputs.offline_mode}}
        run: |
          cp -r /nvme1/shared/qa_test_models/offline_pkg/lmdeploy/opencompass .
          python3 -m pip install lmdeploy-*.whl --no-deps
          python3 -m pip install -r requirements/test.txt -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
      - name: Install lmdeploy - offline
        if: ${{inputs.offline_mode}}
        run: |
          python3 -m pip install /nvme1/shared/qa_test_models/offline_pkg/lmdeploy/lmdeploy-*.whl --no-deps
          python3 -m pip install -r requirements/test.txt -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
      - name: Install opencompass
        run: |
          cd opencompass
          # cp /nvme1/shared/qa_test_models/offline_pkg/requirements-oc.txt requirements/runtime.txt
          python3 -m pip install -e .[full] -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
          echo "OPENCOMPASS_DIR=$(pwd)" >> $GITHUB_ENV
      - name: Check env
        run: |
          python3 -m pip list
          lmdeploy check_env
      - name: Setup paths for evaluation
        run: |
          ln -s /root/opencompass-data ./data
          # python3 .github/scripts/action_tools.py create_model_links /root/models .
      - name: Evaluate chat models
        if: matrix.evaluate_type == 'chat'
        run: |
          echo ${{github.event.inputs.chat_models}}
          echo ${{github.event.inputs.chat_datasets}}
          export LMDEPLOY_DIR=$(pwd)
          python3 .github/scripts/action_tools.py evaluate "${{github.event.inputs.chat_models}}" "${{github.event.inputs.chat_datasets}}" /root/evaluation-reports/${{ github.run_id }} chat 6
      - name: Evaluate base models
        if: matrix.evaluate_type == 'base'
        run: |
          echo ${{github.event.inputs.base_models}}
          echo ${{github.event.inputs.baes_datasets}}
          export LMDEPLOY_DIR=$(pwd)
          python3 .github/scripts/action_tools.py evaluate "${{github.event.inputs.base_models}}" "${{github.event.inputs.baes_datasets}}" /root/evaluation-reports/${{ github.run_id }} base 6
      - name: Clear workspace
        if: always()
        run: |
          export workdir=$(pwd)
          cd ..
          rm -rf $workdir
          mkdir $workdir
          chmod -R 777 $workdir
