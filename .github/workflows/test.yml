name: test_test

on:
  workflow_dispatch:
    inputs:
      models:
        required: true
        description: 'Set models run benchmark'
        type: string
        default: "['internlm/internlm2-chat-20b','internlm/internlm2-chat-20b-inner-w4a16','meta-llama/Llama-2-7b-chat-hf','meta-llama/Llama-2-7b-chat-hf-inner-w4a16']"

env:
  HOST_PIP_CACHE_DIR: /nvme/github-actions/pip-cache
  HOST_LOCALTIME: /usr/share/zoneinfo/Asia/Shanghai
  OUTPUT_FOLDER: cuda11.8_dist_${{ github.run_id }}
  REPORT_DIR: /nvme/qa_test_models/benchmark-reports/${{ github.run_id }}
  DATASET_FILE: /nvme/qa_test_models/datasets/ShareGPT_V3_unfiltered_cleaned_split.json
  TP_INFO: --tp 1
  LOOP_NUM: 3


jobs:
  generation_benchmark:
    runs-on: [self-hosted, linux-a100-2]
    strategy:
      fail-fast: false
      matrix:
        model: ${{fromJSON(github.event.inputs.models)}}
    timeout-minutes: 120
    env:
      MODEL_PATH: /mnt/bigdisk/qa_test_models/${{matrix.model}}
    container:
      image: nvcr.io/nvidia/tritonserver:22.12-py3
      options: "--gpus=all --ipc=host --user root -e PIP_CACHE_DIR=/root/.cache/pip"
      volumes:
        - /nvme/github-actions/pip-cache:/root/.cache/pip
        - /nvme/github-actions/packages:/root/packages
        - /nvme/qa_test_models:/nvme/qa_test_models
        - /mnt/bigdisk/qa_test_models:/mnt/bigdisk/qa_test_models
        - /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro
    steps:
      - name: Clone repository
        uses: actions/checkout@v3
      - name: clone set
        run: chmod +x .github/scripts/env.sh
      - name: Set params - shell
        run: .github/scripts/env.sh
      - name: Set params
        if: contains( matrix.model, 'w4a16') || contains( matrix.model, '4bit')
        run: |
          echo "MODEL_FORMAT=--model-format awq" >> "$GITHUB_ENV"
      - name: Set params
        if: contains( matrix.model, 'llama') || contains( matrix.model, 'Llama')
        run: |
          echo "MAX_ENTRY_COUNT=--cache-max-entry-count 0.95" >> "$GITHUB_ENV"
      - name: Set params
        if: (!contains( matrix.model, 'llama') && !contains( matrix.model, 'Llama'))
        run: |
          echo "MAX_ENTRY_COUNT=--cache-max-entry-count 0.9" >> "$GITHUB_ENV"
      - name: Set params
        if: (contains( matrix.model, 'internlm2-chat-20b'))
        run: |
          echo "TP_INFO=--tp 2" >> "$GITHUB_ENV"
