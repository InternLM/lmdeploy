model_path: /nvme/qa_test_models
resource_path: /nvme/qa_test_models/resource
dst_path: /nvme/qa_test_models/autotest_model
log_path: /nvme/qa_test_models/autotest_model/log
benchmark_path: /nvme/qa_test_models/benchmark-reports
dataset_path: /nvme/qa_test_models/datasets/ShareGPT_V3_unfiltered_cleaned_split.json

tp_config:
    internlm-chat-20b: 2
    internlm2-chat-20b: 2
    Baichuan2-13B-Chat: 2
    Mixtral-8x7B-Instruct-v0.1: 2
    Qwen-VL-Chat: 2
    InternVL2_5-26B: 2
    InternVL2_5-38B: 2
    InternVL2_5-38B-AWQ: 2
    Qwen2.5-14B-Instruct: 2
    Qwen2.5-32B-Instruct: 2
    llava-v1.5-13b: 2
    internlm2_5-20b-chat: 2
    internlm2_5-20b: 2
    Meta-Llama-3-1-70B-Instruct: 4
    internlm2_5-7b-chat-1m: 4
    Qwen2-7B-Instruct-GPTQ-Int4: 2
    InternVL2-26B: 2
    InternVL2-40B: 2
    MiniCPM-V-2_6: 2

turbomind_chat_model:
    - internlm/internlm2_5-7b-chat
    - internlm/internlm2_5-20b-chat
    - internlm/internlm2-chat-20b
    - OpenGVLab/InternVL2_5-1B
    - OpenGVLab/InternVL2_5-2B
    - OpenGVLab/InternVL2_5-8B
    - OpenGVLab/InternVL2_5-26B
    - OpenGVLab/InternVL2_5-38B-AWQ
    - Qwen/Qwen2.5-0.5B-Instruct
    - Qwen/Qwen2.5-1.5B-Instruct
    - Qwen/Qwen2.5-3B-Instruct
    - Qwen/Qwen2.5-7B-Instruct
    - Qwen/Qwen2.5-14B-Instruct
    - Qwen/Qwen2.5-32B-Instruct
    - Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4

pytorch_chat_model:
    - internlm/internlm2_5-7b-chat
    - internlm/internlm2_5-20b-chat
    - internlm/internlm2-chat-20b
    - OpenGVLab/InternVL2_5-1B
    - OpenGVLab/InternVL2_5-2B
    - OpenGVLab/InternVL2_5-4B
    - OpenGVLab/InternVL2_5-8B
    - OpenGVLab/InternVL2_5-26B
    - OpenGVLab/InternVL2_5-38B-AWQ
    - Qwen/Qwen2.5-0.5B-Instruct
    - Qwen/Qwen2.5-1.5B-Instruct
    - Qwen/Qwen2.5-3B-Instruct
    - Qwen/Qwen2.5-7B-Instruct
    - Qwen/Qwen2.5-14B-Instruct
    - Qwen/Qwen2.5-32B-Instruct

turbomind_base_model:
    - internlm/internlm2_5-20b

pytorch_base_model:
    - internlm/internlm2_5-20b

turbomind_vl_model:
    - OpenGVLab/InternVL2_5-1B
    - OpenGVLab/InternVL2_5-2B
    - OpenGVLab/InternVL2_5-8B
    - OpenGVLab/InternVL2_5-26B

pytorch_vl_model:
    - OpenGVLab/InternVL2_5-1B
    - OpenGVLab/InternVL2_5-2B
    - OpenGVLab/InternVL2_5-4B
    - OpenGVLab/InternVL2_5-8B
    - OpenGVLab/InternVL2_5-26B

turbomind_quatization:
    no_awq:
        - meta-llama/Meta-Llama-3-1-70B-Instruct
        - internlm/internlm2_5-20b-chat
        - internlm/internlm2-chat-20b
        - internlm/internlm2_5-20b
        - Qwen/Qwen2.5-72B-Instruct
        - Qwen/Qwen1.5-MoE-A2.7B-Chat
        - Qwen/Qwen2-VL-2B-Instruct
        - Qwen/Qwen2-VL-7B-Instruct
        - mistralai/Mistral-7B-Instruct-v0.3
        - mistralai/Mistral-Nemo-Instruct-2407
        - deepseek-ai/deepseek-coder-1.3b-instruct
        - deepseek-ai/DeepSeek-V2-Lite-Chat
        - codellama/CodeLlama-7b-Instruct-hf
        - allenai/Molmo-7B-D-0924
        - OpenGVLab/InternVL2_5-26B
    gptq:
        - internlm/internlm2_5-7b-chat
    no_kvint4:
        - meta-llama/Llama-3.2-1B-Instruct
        - OpenGVLab/InternVL2-1B
        - OpenGVLab/InternVL2_5-1B
        - openbmb/MiniCPM-V-2_6
        - Qwen/Qwen2-7B-Instruct
        - Qwen/Qwen2-7B-Instruct-AWQ
        - Qwen/Qwen2-1.5B-Instruct
        - Qwen/Qwen2.5-0.5B-Instruct
        - Qwen/Qwen2.5-7B-Instruct
        - Qwen/Qwen2.5-72B-Instruct
        - Qwen/Qwen2-7B-Instruct-GPTQ-Int4
        - allenai/Molmo-7B-D-0924
    no_kvint8:
        - deepseek-ai/DeepSeek-V2-Lite-Chat
    no_converted:
        - deepseek-ai/DeepSeek-V2-Lite-Chat
        - Qwen/Qwen2.5-72B-Instruct
        - meta-llama/Meta-Llama-3-1-70B-Instruct

pytorch_quatization:
    awq:
        - internlm/internlm2_5-7b-chat
        - Qwen/Qwen2.5-7B-Instruct
    w8a8:
        - internlm/internlm2_5-7b-chat
        - internlm/internlm2_5-20b-chat
        - Qwen/Qwen2.5-7B-Instruct
        - Qwen/Qwen2.5-0.5B-Instruct
    no_kvint4:
        - meta-llama/Llama-3.2-1B-Instruct
        - OpenGVLab/InternVL2-1B
        - OpenGVLab/InternVL2-4B
        - OpenGVLab/InternVL2_5-1B
        - Qwen/Qwen2-7B-Instruct
        - Qwen/Qwen2-7B-Instruct-AWQ
        - Qwen/Qwen2-1.5B-Instruct
        - Qwen/Qwen2.5-0.5B-Instruct
        - Qwen/Qwen2.5-7B-Instruct
        - Qwen/Qwen2.5-72B-Instruct
        - Qwen/Qwen2-7B-Instruct-GPTQ-Int4
        - Qwen/Qwen2-VL-2B-Instruct
        - Qwen/Qwen2-VL-7B-Instruct
        - deepseek-ai/DeepSeek-V2-Lite-Chat
        - microsoft/Phi-3-mini-4k-instruct
        - microsoft/Phi-3-vision-128k-instruct
        - microsoft/Phi-3.5-vision-instruct
        - openbmb/MiniCPM-V-2_6
    no_kvint8:
        - deepseek-ai/DeepSeek-V2-Lite-Chat

longtext_model:
    - internlm/internlm2-chat-20b

benchmark_model:
    - internlm/internlm2_5-7b-chat
    - internlm/internlm2_5-20b-chat
    - Qwen/Qwen2.5-7B-Instruct
