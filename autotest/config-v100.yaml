model_path: /nvme/qa_test_models
resource_path: /nvme/qa_test_models/resource
dst_path: /nvme/qa_test_models/autotest_model
log_path: /nvme/qa_test_models/autotest_model/log
benchmark_path: /nvme/qa_test_models/benchmark-reports
dataset_path: /nvme/qa_test_models/datasets/ShareGPT_V3_unfiltered_cleaned_split.json

tp_config:
    internlm2-chat-20b: 2
    Baichuan2-13B-Chat: 2
    Mixtral-8x7B-Instruct-v0.1: 2
    Qwen-VL-Chat: 2
    llava-v1.5-13b: 2
    internlm2_5-20b-chat: 2
    internlm2_5-20b: 2
    Meta-Llama-3-1-70B-Instruct: 4
    internlm2_5-7b-chat-1m: 4
    Qwen2-7B-Instruct-GPTQ-Int4: 2
    InternVL2-26B: 2
    InternVL2-40B: 2
    MiniCPM-V-2_6: 2

turbomind_chat_model:
    - meta-llama/Llama-3.2-1B-Instruct
    - meta-llama/Llama-3.2-3B-Instruct
    - meta-llama/Meta-Llama-3-1-8B-Instruct
    - meta-llama/Meta-Llama-3-1-8B-Instruct-AWQ
    - meta-llama/Meta-Llama-3-8B-Instruct
    - meta-llama/Meta-Llama-3-8B-Instruct-inner-4bits
    - internlm/internlm3-8b-instruct
    - internlm/internlm2_5-7b-chat
    - internlm/internlm2_5-20b-chat
    - internlm/internlm-xcomposer2d5-7b
    - OpenGVLab/InternVL2-1B
    - OpenGVLab/InternVL2-2B
    - OpenGVLab/InternVL2-8B
    - OpenGVLab/InternVL2-26B
    - OpenGVLab/Mini-InternVL-Chat-2B-V1-5
    - Qwen/Qwen2.5-0.5B-Instruct
    - Qwen/Qwen2-7B-Instruct-AWQ
    - Qwen/Qwen2-1.5B-Instruct
    - Qwen/Qwen2.5-7B-Instruct
    - Qwen/Qwen2-7B-Instruct-GPTQ-Int4
    - mistralai/Mistral-7B-Instruct-v0.3
    - THUDM/glm-4-9b-chat


pytorch_chat_model:
    - meta-llama/Meta-Llama-3-8B-Instruct
    - meta-llama/Meta-Llama-3-1-8B-Instruct
    - internlm/internlm3-8b-instruct
    - internlm/internlm2_5-7b-chat
    - internlm/internlm2_5-20b-chat
    - OpenGVLab/InternVL2-1B
    - OpenGVLab/InternVL2-2B
    - OpenGVLab/InternVL2-4B
    - OpenGVLab/InternVL2-8B
    - OpenGVLab/InternVL2-26B
    - Qwen/Qwen2-1.5B-Instruct
    - Qwen/Qwen1.5-MoE-A2.7B-Chat
    - Qwen/Qwen2-VL-2B-Instruct
    - Qwen/Qwen2-VL-7B-Instruct
    - google/gemma-2-9b-it
    - mistralai/Mistral-7B-Instruct-v0.3
    - THUDM/glm-4v-9b
    - THUDM/glm-4-9b-chat
    - microsoft/Phi-3-mini-4k-instruct
    - deepseek-ai/DeepSeek-V2-Lite-Chat

turbomind_base_model:
    - internlm/internlm2_5-7b
    - internlm/internlm2_5-20b

pytorch_base_model:
    - internlm/internlm2_5-7b
    - internlm/internlm2_5-20b

turbomind_vl_model:
    - OpenGVLab/InternVL2-1B
    - OpenGVLab/InternVL2-2B
    - OpenGVLab/InternVL2-8B
    - OpenGVLab/InternVL2-26B
    - Qwen/Qwen2-VL-2B-Instruct
    - Qwen/Qwen2-VL-7B-Instruct
    - internlm/internlm-xcomposer2d5-7b
    - THUDM/glm-4v-9b

pytorch_vl_model:
    - OpenGVLab/InternVL2-1B
    - OpenGVLab/InternVL2-4B
    - OpenGVLab/InternVL2-8B
    - OpenGVLab/InternVL2-26B
    - OpenGVLab/Mono-InternVL-2B
    - Qwen/Qwen2-VL-2B-Instruct
    - Qwen/Qwen2-VL-7B-Instruct
    - THUDM/glm-4v-9b
    - microsoft/Phi-3.5-vision-instruct

turbomind_quatization:
    no_awq:
        - meta-llama/Meta-Llama-3-1-8B-Instruct
        - meta-llama/Meta-Llama-3-8B-Instruct
        - internlm/internlm-xcomposer2d5-7b
        - OpenGVLab/Mini-InternVL-Chat-2B-V1-5
        - Qwen/Qwen2-VL-2B-Instruct
        - Qwen/Qwen2-VL-7B-Instruct
        - mistralai/Mistral-7B-Instruct-v0.3
        - THUDM/glm-4-9b-chat
        - deepseek-ai/deepseek-coder-1.3b-instruct
        - codellama/CodeLlama-7b-Instruct-hf
    gptq:
        - internlm/internlm2_5-7b-chat
    no_kvint4:
        - openbmb/MiniCPM-V-2_6
        - Qwen/Qwen2-7B-Instruct
        - Qwen/Qwen2-7B-Instruct-AWQ
        - Qwen/Qwen2-1.5B-Instruct
        - Qwen/Qwen2.5-0.5B-Instruct
        - Qwen/Qwen2.5-7B-Instruct
        - Qwen/Qwen2-7B-Instruct-GPTQ-Int4
    no_kvint8:
        - deepseek-ai/DeepSeek-V2-Lite-Chat

pytorch_quatization:
    awq:
        - internlm/internlm3-8b-instruct
        - internlm/internlm2_5-7b-chat
        - internlm/internlm2_5-20b-chat
        - Qwen/Qwen2-1.5B-Instruct
    w8a8:
        - internlm/internlm2_5-7b-chat
        - internlm/internlm2_5-7b
    no_kvint4:
        - OpenGVLab/InternVL2-1B
        - OpenGVLab/InternVL2-4B
        - Qwen/Qwen2-7B-Instruct
        - Qwen/Qwen2-1.5B-Instruct
        - Qwen/Qwen2-VL-2B-Instruct
        - Qwen/Qwen2-VL-7B-Instruct
        - deepseek-ai/DeepSeek-V2-Lite-Chat
        - microsoft/Phi-3-mini-4k-instruct
        - microsoft/Phi-3-vision-128k-instruct
        - microsoft/Phi-3.5-vision-instruct
        - openbmb/MiniCPM-V-2_6
    no_kvint8:
        - deepseek-ai/DeepSeek-V2-Lite-Chat

longtext_model:
    - meta-llama/Meta-Llama-3-1-8B-Instruct
    - meta-llama/Meta-Llama-3-8B-Instruct
    - meta-llama/Meta-Llama-3-1-70B-Instruct
    - internlm/internlm2_5-7b-chat-1m
    - internlm/internlm2-chat-20b

benchmark_model:
    - meta-llama/Llama-2-7b-chat-hf
    - meta-llama/Meta-Llama-3-1-8B-Instruct
    - meta-llama/Meta-Llama-3-8B-Instruct
    - meta-llama/Meta-Llama-3-1-70B-Instruct
    - internlm/internlm2_5-7b-chat
    - internlm/internlm2_5-20b-chat
    - THUDM/glm-4-9b-chat
    - mistralai/Mistral-7B-Instruct-v0.3
    - mistralai/Mixtral-8x7B-Instruct-v0.1
    - deepseek-ai/DeepSeek-V2-Lite-Chat
