[llama]
model_name=internlm-20b
;; if turbomind_model_path is provided, the benchmark script won't convert the model in model_path to turbomind_model_path
; turbomind_model_path=/workspace/lmdeploy/benchmark/workspace/turbomind/internlm-chat-20b
model_path=/workspace/models-140/InternLM/internlm-chat-20b
dataset_path=/workspace/lmdeploy/benchmark/ShareGPT_V3_unfiltered_cleaned_split.json
tp=2
tune_gemm=1
w4a16=0
kvint8=0
profile_rpm=1
profile_generation=0
;; the following are engine parameters
max_context_token_num=4
cache_chunk_size=-1
cache_max_entry_count=700
max_batch_size=128
