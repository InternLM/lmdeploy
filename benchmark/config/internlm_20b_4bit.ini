[llama]
model_name=internlm-20b
model_path=/workspace/lmdeploy/benchmark/workspace/quantization/internlm-chat-20b-4bit
dataset_path=/workspace/lmdeploy/benchmark/ShareGPT_V3_unfiltered_cleaned_split.json
tp=2
tune_gemm=0
w4a16=1
kvint8=0
profile_rpm=1
profile_generation=1
;; the following are engine parameters
cache_max_entry_count=0.8
max_batch_size=128
