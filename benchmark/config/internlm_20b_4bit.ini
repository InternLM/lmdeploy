[llama]
model_name=internlm-20b
;; if turbomind_model_path is provided, the benchmark script won't convert the model in model_path to turbomind_model_path
; turbomind_model_path=/workspace/lmdeploy/benchmark/workspace/turbomind/internlm-chat-20b-4bit
model_path=/workspace/models-140/InternLM/internlm-chat-20b
dataset_path=/workspace/lmdeploy/benchmark/ShareGPT_V3_unfiltered_cleaned_split.json
tp=2
tune_gemm=0
w4a16=1
kvint8=0
profile_rpm=1
profile_generation=1
;; the following are engine parameters
cache_max_entry_count=0.75
max_batch_size=128
